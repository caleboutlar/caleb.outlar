{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caleboutlar/caleb.outlar/blob/master/NOvANearAnalysisV2_CalebOutlar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdQ_zgU988Cp"
      },
      "source": [
        "# Data Analysis in Python!\n",
        "Welcome to Python!  Here's a look at another tool or \"venue\" you can also use to analyze data.\n",
        "\n",
        "First, before doing anything else, do a \"File - Save a Copy in Drive\" and Rename the notebook (in the top left).  Know that you can then share your work in this document as you would share any other Google Doc or Sheet.\n",
        "\n",
        "Our goal is not perfect mastery, but to get you started and learn how to work with and edit code \"snippits\" so that they work in your particular application.\n",
        "\n",
        "# What is this document?\n",
        "For some more \"formal\" terminology, this is a \"Jupyter notebook\" with blocks of code called cells. You can press shift+ENTER to run a cell and go on to the next one. You can also edit the code and run it again to see how the output changes.\n",
        "\n",
        "Code in these notebooks also runs from \"top to bottom\" meaning variables and work done in a cell block above can be used in any cell block below it, as long as it has been run.\n",
        "\n",
        "If needed, the \"Runtime\" menu at the top of the screen can also be useful, particularly the \"Run all\" command, as well as the \"Run before\" command.\n",
        "\n",
        "#Importing Python Data Packages\n",
        "To start with, we are going to import some commonly used, mathematical \"packages\" that contain resources we'll want to use in our analysis.  Note that in some programming languages \"packages\" are referred to as \"libraries.\"  More details are in the block of Code below..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgYIOEWC7J56"
      },
      "source": [
        "# Always start by importing the analysis packages we'll be using\n",
        "# Notice that any line that stars with a \" # \" symbol is treated as a \"comment\" in Python, meaning it's for our reference and is not treated as code.\n",
        "\n",
        "import pandas as pd  # Helps with organizing and formatting data.  The \"pd\" is a shorthand reference we can refer to this package as\n",
        "import numpy as np   # \"Num Py\" is a package that contains common mathematical and statistical functions\n",
        "import matplotlib as mpl # \"Mat Plot Lib\" is a package that helps with plotting and graphing data\n",
        "import matplotlib.pyplot as plt  #  \"Py Plot\" is a sub-package of Mat Plot Lib that particularly helps with plotting and graphing data\n",
        "\n",
        "# Also, don't forget to \"run\" this block of code to actually import the packages\n",
        "# To \"Run\" a code block, make sure the cursor is in it and then press \"shift\" and \"enter\" at the same time\n",
        "# You can also an option from the \"Runtime\" menu too.  When running this block, it loads the pacages in the background.\n",
        "# To help assure the cell has run properly, an output line with a message is below...\n",
        "print(\"Packages Imported!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prqrhZ04U6AM"
      },
      "source": [
        "# Basic Math to Get Started\n",
        "First, just to become familiar with math in Python, let's calculate the Far Detector Ratio in the block below..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qljpyBHcU5Sz"
      },
      "source": [
        "# Calculate the Muon Neutrino Event Ratio for the Far Detector (as seen in the images analyzed previously)\n",
        "farNuMuEvents = 19  # Update this value to the number of Far Events that involved a Muon Neutrino\n",
        "farNCEvents = 2319  # Update this value to the number of total Non Charged Far Events\n",
        "farNuMuEventRatio =     # Setup a math calculation in this line, referring to the previously defined variables, to calculate the Far, Muon Neutrino Event Ratio, with comparison to the total number of events\n",
        "farNuMuEventRatio   # A call to the variable alone at the end of the block will print it as an output after this code block is run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__EZEyku-P4z"
      },
      "source": [
        "# Document Goal\n",
        "While the above block introduced some math in Python, it looks at the ratio result from the Far Detector event images.\n",
        "\n",
        "Our goal here, in the remainder of this document, is to produce a similar, \"ratio\" value comparing the number of Muon Neutrino Events to the total Events seen, but for the Near Detector at Fermilab.\n",
        "\n",
        "The Near Detector, being closer, sees quite a few more events, making manual analysis of event images significantly more time consuming.  Instead, let's see if data analysis tools within this Python document can help us analyze the events more efficiently.\n",
        "# Importing Data\n",
        "Now, let's officially turn our analysis to the Near Detector.  A set of event data from the Near Detector is available to you.  As a starting point, we'll want to import it into this Notebook Document to work with.\n",
        "\n",
        "In our notebook, we'll create a \"Pandas Data Frame,\" which is a 2D structure that's able to hold data, and has easy access to many data manipulation and organization tools within the Python environment.\n",
        "\n",
        "There are many ways to import data.  Here we'll use an importing feature that pulls the data in from a \"CSV\" file that's hosted on a web page (GitHub)\n",
        "\n",
        "[If you need help with this step, a Screen Shot Tutorial can be found here.](https://docs.google.com/document/d/1bvTkJ6INfPW8tPc-m2EJBHTNpHAFLajMevA-fa_9vug/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gd25NCuFMgC"
      },
      "source": [
        "# Importing data into a Dataframe from a web based source\n",
        "# For this activity, Near NOvA Event Data can be found at this website:  https://github.com/ThePAEngineer/NOvAData\n",
        "# The file you'll want to focus on is called:  NOvA-ND-Events.csv\n",
        "# Once there, click on the file of interest, then copy the link from the \"Raw\" button, pasting it in the indicated space below\n",
        "\n",
        "dataImported = pd.read_csv('web link here')\n",
        "dataImported.head()  # A call to the \"head\" function prints out the first few rows to verify the data was correctly imported\n",
        "\n",
        "# As always, don't forget to \"Run\" this cell when ready!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-25bbBUwFwtL"
      },
      "source": [
        "# Our Coding Method - Modification & Fixing Given Code Blocks\n",
        "Much of what we'll do in our analysis work will be about modifying given code blocks to accomplish the task needed.  You just did this in the previous cells, taking a pre-made chunk of code and modifying the web link to the needed space.\n",
        "\n",
        "The goal isn't Python mastery, but the ability to experience what Python can do for you in the data analysis world, and also gain familiarity with how to use and modify provided Python code to accomplish a data analysis task.\n",
        "\n",
        "You can further modify this code, if interested, by, say, including a value in the call to the \"head\" function.  \n",
        "\n",
        "**Try changing the last code line from the previous cell to:  dataImported.head(10)**\n",
        "\n",
        "Then run the cell and see what happens.\n",
        "\n",
        "# Manipulation of Data in a Data Frame\n",
        "With the raw data imported, it's good to take a moment and perform some reorganization, as well as some initial data manipulation as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKiSPQ9OHcyq"
      },
      "source": [
        "# Raw data can be harder to work with, even it's titles, so creating a new data frame to hold easier to type & reference names can be usefull.  See below...\n",
        "data = pd.DataFrame() # create a new, empty dataframe.  Once it's made, it only needs to be created once.\n",
        "\n",
        "data['longest'] = dataImported['Longest Track Length (cm)'] # add a new column, with an easier to reference title, that's equal to an original data column\n",
        "data.head() # verify that it worked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lGXXKvMZ6hP"
      },
      "source": [
        "# Complete the following 2 lines to transfer the remaining data into our new, easier to use dataframe\n",
        "data['2ndLongest'] = _________\n",
        "data[_________________________\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHLMQGgLcGQs"
      },
      "source": [
        "# Viewing the Raw Data\n",
        "With the move to a new, easier to reference Data Frame, the next move could be to get an overview of what is present within the data.  Some ideas for doing this are below.  Referencing the \"Sample\" document can also be helpful too..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfR1EvVQcF96"
      },
      "source": [
        "# A call to the \"describe\" function can help give a numerical overview.\n",
        "# It can be used for all columns, as seen below, or a reference to a particular column can be made too\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to pause and think about what the above values from the \"describe\" call mean...\n",
        "- How many \"Events\" are in the Near Detector data set?  Is this what was expected?  How does this compare to the Far Detector?\n",
        "- Note the \"Mean\" values from the longest, 2nd longest, and 3rd longest tracks from the events as well\n",
        "\n",
        "Next we'll view the data visually using a Histogram.  The \"Range\" of the column with the largest span can be helpful to note as well when preparing a histogram."
      ],
      "metadata": {
        "id": "NvLmzWkCFRP7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5mZ_supb8ib"
      },
      "source": [
        "# These are all values of similar events, so a visual look using a histogram may also be useful\n",
        "# The sample document contains the code for a histogram, but multiple data sets can be \"stacked\" on the same graph\n",
        "# by repeating the line that creates the histogram.  See below and complete...\n",
        "plt.hist(data['longest'],range=[___lowestRangeHere___,___highestRangeHere___], bins=10, log=False, alpha = 0.5, label='longest')  # makes the histogram.  \"alpha\" refers to transparency of the bar on the graph\n",
        "plt.hist(data['2ndLon______________'    # make a histogram for each additional column in the data set to view & compare their values visually\n",
        "plt.hist(dat___________________________\n",
        "plt.title(\"PlotTitleHere\")\n",
        "plt.xlabel(\"HorizontalAxisTitle\")\n",
        "plt.ylabel(\"VerticalAxisTitle\")\n",
        "plt.legend(loc ='upper right') # Displays a legend for help in identifying each set of data being plotted on the single histogram\n",
        "# If interested, the above uses the \"MathPlotLib\" library set to create the histogram.  This library has lots of tools for making graphs in Python.\n",
        "# A Google Search as well as looking at the provided \"Sample\" document shows some more of the graphing options available in this library.\n",
        "plt.grid(False);\n",
        "\n",
        "# Feel free to play with the above.  Some strategic commenting (notice comments lead with the # sign) of lines can help strategically view the data as well"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What do you notice?\n",
        "- How does the shape of the histograms here compare to the Far Detector histograms you saw earlier (based on the images)?\n",
        "- When completing analysis of the Far Detector events earlier today, which \"track\" did you focus on (Longest, 2nd Longest, 3rd Longest) from the images?\n",
        "- Which track should be focused on here, now looking at the Near Detector events?"
      ],
      "metadata": {
        "id": "V5v9yv1X3lN7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NefEC9Wpjz5l"
      },
      "source": [
        "# Ratio & Event Counting\n",
        "Next up, we'd like to find a ratio of muon neutrino interactions, compared to the overal number of interactions present."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall your analysis work from earlier today...\n",
        "# From the Far Detector Event Images, What Length Value was agreed upon\n",
        "# to help determine if an event was a NuMu event (and not an NC event)?\n",
        "\n",
        "nuMuEventTrackLength = 42  # This number should be updated\n",
        "print(\"NuMu Event Length Value: \", nuMuEventTrackLength)"
      ],
      "metadata": {
        "id": "-WMmIn6S3vmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nXmx7yykjV9"
      },
      "source": [
        "# The numpy library has a \"sum\" function that can be called.\n",
        "# The numpy library is the place to go when wanting to do beyond basic math and statistical analysis work in Python.\n",
        "# When used with a logical expression, the number of events that evaluate to \"true\" are then counted and returned...\n",
        "\n",
        "nearNuMuEventCount = np.sum(data['***Column_Of_Interest***'] > ***Length_Limit_Variable_Here***)  #Update the references in this line as needed so the result contains the representative number of muon neutrino events from the data set.\n",
        "print(\"Near NuMu Event Count: \", nearNuMuEventCount)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7yg1Povk4Kp"
      },
      "source": [
        "# A ratio could be found by dividing the \"count\" by the length of the data set\n",
        "# Update the below line as needed to probably create the end ratio, relating number of muon neutrino events to the total number of events\n",
        "nearDetectorRatio = nearNuMuEventCount / len(data['***columnOfInterest***'])\n",
        "print(\"Near Detector NuMu Event Ratio: \", nearDetectorRatio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkDr5zB2ck7z"
      },
      "source": [
        "# A reference back to the original, Far Event Ratio calculated at the begining of the document can help for easier comparison too...\n",
        "# Make a single line call to that variable here, to print it so we can easily view it against the just calculated Near Event Ratio\n",
        "farNuMu________"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvzVcDTLlRv2"
      },
      "source": [
        "# Final Thoughts\n",
        "With the ratio above, compare this value to the ratio seen from the Far Detector Event images that were analyzed earlier.\n",
        "\n",
        "Are they the same, different?  How do you know?...See below for some more Python based analysis...\n",
        "\n",
        "What does this mean about the neutrino flavors seen at the near detector...the far detector...?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A Percent Difference Calculation Could be Used\n",
        "# to Help Decide if the 2 Values are Different\n",
        "# Try this out using the very formal definition...\n",
        "#  ( |Got - Shoulda Got| / Shoulda Got ) X 100\n",
        "# Here the \"Shoulda Got\" value could be the Far Event Ratio\n",
        "\n",
        "eventPercentDiff = (np.abs(nearD________\n",
        "\n",
        "print(\"Event Percent Difference: \", eventPercentDiff)"
      ],
      "metadata": {
        "id": "hbXafpzu5Lec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional comparison analysis could come from creating a \"max\" and \"min\" ratio value for the Near Detector results.\n",
        "# The definition of the length, cut-off value probably has some room for discussion\n",
        "# Looking back at the spreadsheet analysis to determine the length used could help with this.\n",
        "# Define a \"low\" and a \"high\" length value and see if the resulting ratio range could include the Far Detector Ratio Result\n",
        "\n",
        "minNearNuMuEventsCount = __________\n",
        "maxNearNuMuEventsCount = __________\n",
        "\n",
        "minRatioNear = ______________\n",
        "maxRatioNear = ______________\n",
        "\n",
        "print(\"Low Ratio Near NuMu Events: \", minRatioNear, \" High Ratio Near NuMu Events: \", maxRatioNear)\n",
        "print(\"Far NuMu Event Ratio: \", farNuMu_______)"
      ],
      "metadata": {
        "id": "IrSV2Q9u_CFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Like Coding...Want Another Resource?\n",
        "\n",
        "If you're looking for a way to continue to use Python to analyze data but want some additional reference code blocks, the document linked below contains several, data analysis useful, Code Blocks.\n",
        "\n",
        "[Sample Code Block Document Link](https://drive.google.com/file/d/1Gkm2CQndWhxXpAZssPBDvaY-KdSjzl3e/view?usp=sharing)\n",
        "\n",
        "Feel free to do a \"File - Save a Copy in Drive\" on this document so you can have it, keep it, and use it in your future Python work."
      ],
      "metadata": {
        "id": "vsKSMSA6vcZ-"
      }
    }
  ]
}